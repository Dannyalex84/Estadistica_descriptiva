Estad√≠stica descriptiva vs. inferencial
Es importante entender la diferencia entre las dos principales ramas de la estad√≠stica en el area de las matem√°ticas:

Estad√≠stica descriptiva: Se trata de resumir informaci√≥n de manera cuantitativa para entender de forma sencilla y concreta sobre alg√∫n determinado asunto
Estad√≠stica inferencia: Se basa en realizar inferencias, deducir que podr√≠a pasar en el futuro en base a lo datos que tenemos acceso en la actualidad
¬øPuede mentir la estad√≠stica?

La estad√≠stica descriptiva tiene un problema al momento de definir que m√©trica es la que nos va a brindar la mayor relevancia para nuestro estudio.

El resultado podr√≠a estar sesgado a nuestro criterio personal, mostrando mayor inter√©s a un cierto par√°metro. dejando de lado a otro que tambi√©n podr√≠a ser relevante. Mostramos solo una cara de la moneda.
No existen definiciones objetivas en estad√≠stica, sin embargo sobre estas definiciones podemos realizar c√°lculos exactos lo cual es un problema
Los diferentes estad√≠sticos descriptivos dan nociones diferentes sobre los mismos datos.
¬øPor que aprender estad√≠stica?

A pesar de los problemas que pueda presentar es muy importante entender que la estad√≠stica nos puede ayudar a:

Resumir grandes cantidades de informaci√≥n
tomar mejores decisiones
responder preguntas con relevancia social
reconocer patrones en los datos
descubrir a quien usan estas herramientas con fines nefastos


Estadistica descriptiva: Se encarga de resumir, describir la situaci√≥n actual de un evento a trav√©s de los datos. nos dan nociones mas claras o difretentes a cerca de un evento; si pudiera explicarlo con una analogia es como estar en lo alto de una monta√±a e intentar ver un paisaje a lo lejos (datos) pero solo vez con escaso detalle, formas o siluetas, entonces te pones unos binoculares (usas la estadistica descriptiva) y ya puedes ver con mas claridad q hay arbolitos, un arrollo, a lo mejor q hay personas o tal vez unas casas un lado etc.

Est√°distica inferencial: Esta asociada a deducir, predecir, o hacer inferencia a tr√°ves de los datos; con la misma analogia de los binoculares la estadistica inferencia vendria siendo como una bola de cristal q te permite ver un posible futuro (como la de uranai baba de dragon ball xD); tal vez no a predecir con exactitud que va a pasar pero si nos da certidumbre estadistica a cerca de eventos.


¬øQu√© es la estad√≠stica descriptiva vs. inferencial?

Son las dos principales ramas de la estad√≠stica

La descriptiva busca resumir informaci√≥n hist√≥rica.
La inferencial busca inferir una predicci√≥n.

En la estad√≠stica descriptiva:

Permite ‚Äúmentir‚Äù, ya que no hay una definici√≥n objetiva

Depender√° de qu√© ‚Äúlado de la moneda‚Äù se muestre

Se puede llegar a distintas conclusiones dependiendo del peso que se le d√© a cada variable

Los estad√≠sticos descriptivos dan nociones diferentes sobre los mismos datos

LEER NAKED STATISTICS

¬øPor qu√© aprender estad√≠stica?

Resumir grandes cantidades de informaci√≥n
Tomar mejores decisiones
Responder preguntas con relevancia social
Reconocer patrones en los datos
Descubrir a quienes usan estas herramientas con fines nefastos


La estad√≠stica descriptiva tiene como objetivo resumir la informaci√≥n contenida en los datos de la forma m√°s sencilla y presentable posible, obteniendo as√≠ los par√°metros que distinguen las caracter√≠sticas de un conjunto de datos (lo que se conoce como estad√≠sticos). Pertenecen al √°mbito de la estad√≠stica descriptiva las tablas de frecuencias, a partir de las cuales se obtienen los estad√≠sticos:

Medidas de centralizaci√≥n: la media en todas sus variantes (aritm√©tica, geom√©trica, ponderada), la moda y la mediana
Medidas de dispersi√≥n: la varianza, la desviaci√≥n t√≠pica (ra√≠z cuadrada de la varianza) y el rango
Medidas de tendencia central: los cuantiles y sus desgloses (percentiles, cuartiles, deciles, etc.)
Medidas de forma: los coeficientes de asimetr√≠a y curtosis
Medidas de concentraci√≥n: el coeficiente Gini, a partir del cual se obtiene la curva de Lorenz
Etc. etc. etc.

¬øQu√© es lo que distingue a la estad√≠stica descriptiva de la inferencial?

En primer lugar, la naturaleza de los datos. Mientras que la estad√≠stica descriptiva sirve tanto para una poblaci√≥n como para una muestra (un subconjunto de esa poblaci√≥n cuyos elementos son elegidos al azar), la estad√≠stica inferencial trabaja con muestras a partir de las cuales intenta extraer conclusiones sobre la poblaci√≥n.

Esta pr√°ctica se conoce como inferir, y es importante recalcar la diferencia en la naturaleza de los datos, ya que es un error muy com√∫n el de extraer conclusiones de un conjunto cuyas conclusiones‚Ä¶ son los mismos datos en s√≠.

Para explicar dicho error, conviene asimismo explicar la principal diferencia te√≥rica entre estad√≠stica descriptiva e inferencial. La descriptiva, al ser √∫nicamente una descripci√≥n de los datos, no asume que √©stos tengan alguna propiedad m√°s all√° de las que se pueden describir con los estad√≠sticos ya mencionados. En cambio, la inferencial asume que los datos se rigen bajo un fen√≥meno aleatorio subyacente que es el que hace que tomen un valor u otro. Es por esto por lo que los datos pasar√≠an a denominarse variables aleatorias. Al existir incertidumbre, se puede igualmente describir la poblaci√≥n de la que sale esa muestra, pero debemos entonces asumir un cierto error derivado de la naturaleza probabil√≠stica de los datos.


¬øQu√© es la estad√≠stica descriptiva?

La estad√≠stica descriptiva, tambi√©n conocida como ¬´muestras¬ª puede determinar m√∫ltiples observaciones que se realizan a lo largo de la investigaci√≥n. Se define como la b√∫squeda de miembros de grupos que se ajusten a los par√°metros de tu investigaci√≥n, la anotaci√≥n de datos sobre los grupos que est√°s probando y la aplicaci√≥n de estad√≠sticas y gr√°ficos para concluir las conclusiones de este grupo. En otras palabras, se trata de reducir los resultados de este grupo a unos pocos puntos clave.

En este caso, usted‚Äô s√≥lo trata de probar los resultados que puede obtener de los individuos relevantes. Esto le obliga a seguir probando si sus resultados afectan a una parte mayor de la poblaci√≥n.

Algunas conclusiones para las que se puede medir son:

Tendencia central: El proceso de utilizar la media y la mediana para determinar la ubicaci√≥n de los puntos de datos en un gr√°fico.

Dispersi√≥n: La dispersi√≥n es otra forma de identificar la separaci√≥n de los puntos de datos del centro de tu gr√°fico. Un n√∫mero peque√±o significa que la dispersi√≥n est√° m√°s cerca del centro, mientras que un n√∫mero mayor implica una mayor separaci√≥n del epicentro del gr√°fico.

Asimetr√≠a: La asimetr√≠a destaca la separaci√≥n de los puntos de datos que has medido entre s√≠. Puede concluir si son sim√©tricos o sesgados a partir de sus mediciones.

**** ¬øQu√© es la estad√≠stica inferencial?****

La estad√≠stica inferencial es cuando se toman datos de un grupo de muestra y se hace una predicci√≥n que repercute en la conclusi√≥n sobre una poblaci√≥n grande. Puedes utilizar el muestreo aleatorio para evaluar c√≥mo las diferentes variables pueden llevarte a hacer generalizaciones para realizar m√°s experimentos. Para obtener un an√°lisis preciso, tendr√° que identificar la poblaci√≥n que est√° midiendo, crear una muestra para esa poblaci√≥n e incorporar el an√°lisis para encontrar un error de muestreo.


Estad√≠stica
Podemos enteder la estad√≠stica como el estudio y la pr√°ctica de recolectar informaci√≥n y describirla de una manera que resulte √∫til. Por supuesto, esta utilidad depende de la finalidad con que nosotros estamos realizando nuestros estudios: qu√© preguntas queremos responder. ü§î
.

Estad√≠stica descriptiva
Si tenemos un conjunto de datos, recolectado de una muestra, la estad√≠stica descriptiva se enfoca en describir este conjunto de datos de forma sintetizada (unos cuantos n√∫meros) pero a√∫n √∫til para nuestros fines. Tenemos medidas de tendencia central y medidas de dispersi√≥n para describir nuestro data set. üìä
.

Estad√≠stica inferencial
Dado un conjunto de datos extra√≠do del estudio de una muestra, la estad√≠stica inferencial se enfoca en tratar de extraer conclusiones que sean validas para una poblaci√≥n m√°s grande que con la que se pudo interactuar.
.
Nosotros no podemos hacer un estudio sobre los efectos secundarios de un medicamento, que involucre a todas las personas en la tierra. Aqu√≠ la estad√≠stica inferencial nos ayudar√≠a a tratar de obtener conclusiones validas para todas las personas en la tierra, a√∫n cuando s√≥lo una fracci√≥n de este total haya tenido contacto con el medicamento. üìà


Mentiras, malditas mentiras y estad√≠sticas
El arte de mentir
El mundo que nos rodea es cada vez m√°s complejo. Nos estamos concentrando en la creciente complejidad matem√°tica de nuestra sociedad en sus diversas facetas. Queremos crear una nueva conciencia contra el mal uso cotidiano de las matem√°ticas proporcionando varios ejemplos protot√≠picos de usos falsos y enga√±osos de los m√©todos matem√°ticos. Esperamos que se vuelva m√°s esc√©ptico despu√©s de haber le√≠do los diversos ejemplos, que cubren casi todas las √°reas de nuestra sociedad. Podr√°s diferenciar entre el bien del mal y los hechos de las mentiras.

Mentir con estad√≠sticas es f√°cil, de hecho, puede ser realizado f√°cilmente por aficionados a las matem√°ticas. Nadie discutir√≠a seriamente que hay personas que no pueden ver nada. Tambi√©n hay personas dalt√≥nicas, que ven el mundo desde otra perspectiva. Muchos de ellos no pueden ver, por ejemplo, cerezas en un cerezo. Pero casi nadie sabe acerca de la ceguera matem√°tica. La ceguera num√©rica puede llegar a ser innumerable.

Si bien el analfabetismo se discute p√∫blicamente con mucha frecuencia, casi nadie habla de la falta de aritm√©tica. Al menos el idioma ingl√©s tiene una palabra para aquellos que carecen de conocimiento y comprensi√≥n de conceptos y m√©todos matem√°ticos. No hay una palabra para ‚Äúinnumerado‚Äù ni para ‚Äúinnumeraci√≥n‚Äù en el idioma alem√°n. Si un concepto no es generalmente conocido o no se tiene en cuenta, es posible que no haya una palabra para describirlo. P.ej. no existe una palabra para nieve en algunos idiomas africanos, mientras que los esquimales tienen diferentes palabras para varios tipos de nieve. Pero te equivocas si crees que el aritm√©tica est√° ausente en Alemania como no hay nieve en muchas zonas de √Åfrica. La ignorancia matem√°tica est√° tan extendida en Alemania como en otros pa√≠ses llamados civilizados. El principal problema radica en el hecho de que muchos adultos ‚Äúeducados‚Äù son funcionalmente innumerables. Esto significa, en muchos casos, que no son capaces de manejar conceptos como presentaciones gr√°ficas de datos, estimaci√≥n de riesgos y carecen de la l√≥gica para el an√°lisis estad√≠stico.

La principal diferencia con ser analfabeto es que la mayor√≠a de las personas ni siquiera se dan cuenta de que les afecta. Es una enfermedad de la que ni siquiera los matem√°ticos est√°n completamente libres.

Desafortunadamente, puede usarse como un libro de texto para aquellos que quieren comenzar a hacer trampa por su cuenta.


¬øEn que partes del flujo de trabajo se necesita de estad√≠stica?
.
Todos las partes del flujo requiere del conocimiento en ciertas ramas de la estad√≠stica. La estad√≠stica descriptiva se va a emplear m√°s en los dos primeros bloques de trabajo.

.

Ingesta de datos y Validaci√≥n : Se encarga de todo el procesamiento de ETL (Extract Transform Load) obtener los datos, limpiarlos y estructurarlos, crear pipelines de an√°lisis automatizado, es decir que transformaciones vamos a realizar a los datos para que est√©n listos para el caso especifico de estudio que vamos a realizar.

Preparaci√≥n y entrenamiento del modelo: En este bloque se va a realizar un an√°lisis exploratorio de los datos con estad√≠stica descriptiva, entender correlaciones y realizar posibles reducciones de datos.

Evaluar el modelo, Producci√≥n e Interacci√≥n: esta parte del flujo se basa mas en la estad√≠stica inferencial.

El flujo de trabajo en Data Science tiene 8 pasos:

Data ingestion.
Data visualization.
Data preparation.
Model training .
Model evaluation.
Model validation.
Model serving.
En user interface.
En algunos de estos se puede aplicar la estad√≠stica, por ejemplo, en los primeros cuatro la estad√≠stica descriptiva juega un rol importante.

El flujo suele estar compuesto por el pipeline OSEMN, es decir:

O => Obtaining data
S => Scrubbing / Cleaning data
E => Exploring / Visualizing data
M => Modeling data
N => Interpreting data
Los roles son:

Ingeniero de datos
Analista de datos
Cient√≠fico de datos gen√©rico
Ingeniero de Machine Learning
Cient√≠fico investigador
Todos los roles necesitan saber estad√≠stica en las fases que les corresponde desarrollar en el flujo.
.
Se puede dividir el flujo de trabajo en 3 bloques:
‚Ä¢ Ingesta de datos y Validaci√≥n :
Se encarga de todo el procesamiento de ETL (Extract Transform Load). Ahi vamos a obtener los datos, limpiarlos y estructurarlos, crear pipelines para definir que transformaciones vamos a realizar a los datos para que est√©n listos para el caso espec√≠fico de estudio que vamos a realizar.
‚Ä¢ Preparaci√≥n y entrenamiento del modelo:
En este bloque se toma los datos preparados y se construye el modelo. Aqui se va a realizar un an√°lisis exploratorio de los datos con estad√≠stica descriptiva, entender correlaciones y realizar posibles reducciones de datos.
‚Ä¢ Evaluar el modelo, Producci√≥n e Interacci√≥n:
esta parte del flujo se basa m√°s en la estad√≠stica inferencial.


Dato curioso: ¬øCu√°l es la diferencia entre un diagrama de frecuencias (gr√°fica de barras) y un histograma
.
El diagrama de frecuencias (gr√°fica de barras) sirve para representar las variables cualitativas ordinales. En el eje horizontal se representan las diferentes categor√≠¬≠as y sobre √©l se levantan unas columnas o barras cuya altura es proporcional a la frecuencia de cada categor√≠¬≠a. Tambi√©n podr√≠¬≠amos utilizar este tipo de gr√°fico para representar variables cuantitativas discretas, pero lo que no es correcto hacer es usarlo para las variables cualitativas nominales.
El gran m√©rito del diagrama de barras es expresar la magnitud de las diferencias entre las categor√≠¬≠as de la variable. Pero ah√≠¬≠ est√° precisamente, su punto d√©bil, ya que son f√°cilmente manipulables si modificamos los ejes.
.
El histograma es un gr√°fico con un significado mucho m√°s profundo. Un histograma representa una distribuci√≥n de frecuencias que se utiliza (o debe) para representar la frecuencia de las variables cuantitativas continuas. Aqu√≠¬≠ no es la altura, sino el √°rea de la barra lo que es proporcional a la frecuencia de ese intervalo, y est√° en relaci√≥n con la probabilidad con la que cada intervalo puede presentarse.
Otra diferencia muy importante entre el diagrama de barras y el histograma es que en el primero solo se representan los valores de las variables que hemos observado al hacer el estudio. Sin embargo, el histograma va mucho m√°s all√°, ya que representa todos los valores posibles que existen dentro de los intervalos, aunque no hayamos observado ninguno de forma directa. Permite as√≠¬≠ calcular la probabilidad de que se represente cualquier valor de la distribuci√≥n, lo que es de gran importancia si queremos hacer inferencia y estimar valores de la poblaci√≥n a partir de los resultados de nuestra muestra.


Medidas de dispersi√≥n
Rango: El Rango es el intervalo entre el valor m√°ximo y el valor m√≠nimo.

Cuartiles: Los cuartiles son valores que dividen una muestra de datos en cuatro partes iguales.

1er cuartil (Q1): 25% de los datos es menor que o igual a este valor.
2do cuartil (Q2): La mediana. 50% de los datos es menor que o igual a este valor.
3er cuartil (Q3): 75% de los datos es menor que o igual a este valor.
Rango intercuartil: La distancia entre el primer 1er cuartil y el 3er cuartil (Q3-Q1); de esta manera, abarca el 50% central de los datos.
Diagrama de caja o box plot: representa gr√°ficamente una serie de datos num√©ricos a trav√©s de sus cuartiles. De esta manera, el diagrama de caja muestra a simple vista la mediana y los cuartiles de los datos. Tambi√©n puede representar los valores at√≠picos de estos.

Desviaci√≥n est√°ndar
La desviaci√≥n est√°ndar es la medida de dispersi√≥n m√°s com√∫n, que indica qu√© tan dispersos est√°n los datos con respecto a la media. Mientras mayor sea la desviaci√≥n est√°ndar, mayor ser√° la dispersi√≥n de los datos.
El s√≠mbolo œÉ (sigma) se utiliza frecuentemente para representar la desviaci√≥n est√°ndar de una poblaci√≥n, mientras que s se utiliza para representar la desviaci√≥n est√°ndar de una muestra.
La desviaci√≥n est√°ndar se puede utilizar para establecer un valor de referencia para estimar la variaci√≥n general de un proceso.

Solo para aclarar, ya que el termino de varianza se abordo muy r√°pidamente:

Varianza: es una medida de dispersi√≥n que representa la variabilidad de una serie de datos respecto a su media. Formalmente se calcula como la suma de los residuos al cuadrado divididos entre el total de observaciones. Su f√≥rmula es la siguiente:
X ‚Üí Variable sobre la que se pretenden calcular la varianza
xi ‚Üí Observaci√≥n n√∫mero i de la variable X. i puede tomar√° valores entre 1 y n.
N ‚Üí N√∫mero de observaciones.
xÃÑ ‚Üí Es la media de la variable X.
La diferencia entre la desviaci√≥n est√°ndar o t√≠pica y la varianza, es que la la desviaci√≥n t√≠pica es la ra√≠z cuadrada de la varianza
.
Y no nos podemos olvidar de otra medida de dispersi√≥n muy importante, que es el coeficiente de variaci√≥n:

Su c√°lculo se obtiene de dividir la desviaci√≥n t√≠pica entre el valor absoluto de la media del conjunto y por lo general se expresa en porcentaje para su mejor comprensi√≥n.

X ‚Üí Variable sobre la que se pretenden calcular la varianza
œÉx ‚Üí Desviaci√≥n t√≠pica de la variable X.
| xÃÑ | ‚Üí Es la media de la variable X en valor absoluto con xÃÑ ‚â† 0
El coeficiente de variaci√≥n de utiliza para comparar la dispersi√≥n (variaci√≥n) de conjuntos de datos de medidas diferentes o con medias aritm√©ticas diferentes.


$$ \sqrt {\frac{1}{N}\sum\limits_{i = 1}^N {\left( {x_i - \bar x} \right)^2 } } $$


Asimetr√≠a en distribuciones
Como vimos en la clase, el hecho de que nuestra distribuci√≥n tenga una tendencia a la derecha o a izquierda nos representa un problema, ya que no a acorde con una distribuci√≥n y eso puede afectar a nuestros an√°lisis si no tomamos en cuenta ese sesgo. No siempre hay que confiar en nuestra intuici√≥n o lo que vemos a simple vista, hay m√©todos como:

Primer coeficiente de asimetr√≠a de Pearson (asimetr√≠a de modo)
Segundo coeficiente de asimetr√≠a de Pearson (asimetr√≠a mediana)
Coeficiente de Groeneveld y Meeden
Coeficiente de Fisher
Por mencionar algunos.
.

Y por √∫ltimo, no hay que olvidar la curtosis:
Una curtosis grande implica una mayor concentraci√≥n de valores de la variable tanto muy cerca de la media de la distribuci√≥n (pico) como muy lejos de ella (colas), al tiempo que existe una relativamente menor frecuencia de valores intermedios. Esto explica una forma de la distribuci√≥n de frecuencias/probabilidad con colas m√°s gruesas, con un centro m√°s apuntado y una menor proporci√≥n de valores intermedios entre el pico y colas.
Una mayor curtosis no implica una mayor varianza, ni viceversa.

Normalizaci√≥n
La normalizaci√≥n es una t√©cnica que a menudo se aplica como parte de la preparaci√≥n de datos para el aprendizaje autom√°tico. El objetivo de la normalizaci√≥n es cambiar los valores de las columnas num√©ricas en el conjunto de datos para usar una escala com√∫n, sin distorsionar las diferencias en los rangos de valores ni perder informaci√≥n. La normalizaci√≥n tambi√©n es necesaria para que algunos algoritmos modelen los datos correctamente.
.
Por ejemplo, suponga que su conjunto de datos de entrada contiene una columna con valores que van de 0 a 1 y otra columna con valores que van de 10,000 a 100,000. La gran diferencia en la escala de los n√∫meros podr√≠a causar problemas al intentar combinar los valores como caracter√≠sticas durante el modelado.
.
La normalizaci√≥n evita estos problemas al crear nuevos valores que mantienen la distribuci√≥n general y las proporciones en los datos de origen, mientras mantienen los valores dentro de una escala aplicada en todas las columnas num√©ricas utilizadas en el modelo.
.

Tenemos varias opciones para transformar datos num√©ricos:
Cambiar todos los valores a una escala de 0 a 1 o transformar los valores represent√°ndolos como rangos de percentiles en lugar de valores absolutos.
Aplicar la normalizaci√≥n a una sola columna o a varias columnas en el mismo conjunto de datos.
Si necesita repetir el experimento o aplicar los mismos pasos de normalizaci√≥n a otros datos, puede guardar los pasos como una transformaci√≥n de normalizaci√≥n y aplicarlos a otros conjuntos de datos que tengan el mismo esquema.
Nota importante: Algunos algoritmos requieren que los datos se normalicen antes de entrenar un modelo. Otros algoritmos realizan su propia normalizaci√≥n o escalado de datos.

Normalizaci√≥n lineal
Algunos de los tipos:

Zscore : convierte todos los valores en una puntuaci√≥n z. Los valores de la columna se transforman mediante la siguiente f√≥rmula:
z score
La media y la desviaci√≥n est√°ndar se calculan para cada columna por separado. Se utiliza la desviaci√≥n est√°ndar de la poblaci√≥n.


MinMax : el normalizador min-max cambia la escala linealmente cada caracter√≠stica al intervalo [0,1]. El cambio de escala al intervalo [0,1] se realiza cambiando los valores de cada caracter√≠stica para que el valor m√≠nimo sea 0, y luego dividiendo por el nuevo valor m√°ximo (que es la diferencia entre los valores m√°ximo y m√≠nimo originales). Los valores de la columna se transforman mediante la siguiente f√≥rmula:
min max


¬øCu√°ndo usar la normalizaci√≥n lineal?
En datos sim√©tricos o en datos uniformemente distribuidos.

Escalamiento lineal

T√©cnica para normalizar los datos usando una escala com√∫n en las variables de inter√©s antes de modelar o desarrollar un aprendizaje autom√°tico. Transforma el valor de cada dato para un rango determinado. Normalmente [-1,1]

Min-Max: Transforma cada dato (X) a un valor normalizado ($X_s$) usando el valor m√≠nimo y m√°ximo de cada variable
$$ X_s = (2X-min-max)/(max-min) $$

Clipping: Corta la distribuci√≥n de los datos entre dos valores limite. El valor de cada dato fuera de los limites colapsa al valor del limite mas cercano.

Winzoriding: Usando percentiles espec√≠ficos de limites.
Z-Score: Se determina usando medidas de tendencia central y de dispersi√≥n.

$$ X_s = ( X - Promedio) / Desv. Stand $$

Resumen de clase:
Todo lo anterior visto sirve para identificar el uso de estad√≠stica descriptiva en el an√°lisis de exploraci√≥n de datos.
El an√°lisis exploratorio de datos no se reduce a la visto en estad√≠stica descriptiva.
En esta secci√≥n se enfoca en el uso de estad√≠stica descriptiva para el procesamiento de datos pre modelo predictivo.
.
Escalamiento o normalizaci√≥n lineal
¬øQu√© es?
La normalizaci√≥n es una t√©cnica que a menudo se aplica como parte de la preparaci√≥n de datos para el aprendizaje autom√°tico.
¬øEn qu√© consiste?
En cambiar los valores de las columnas num√©ricas en el conjunto de datos para usar una escala com√∫n, sin distorsionar las diferencias en los rangos de valores ni perder informaci√≥n.
¬øPor qu√© usarlos?
Los modelos de machine Learning son eficientes en el rango [-1,1]. Si los datos no se encuentran en ese rango debes transformarlos mediante el escalamiento o normalizaci√≥n para que los algoritmos modelen los datos correctamente.
¬øCu√°ndo usarlos?
Data sim√©trica o uniformemente distribuida. Un ejemplo de ellos es la distribuci√≥n Gaussiana.
Usando el box-splot y el histograma podremos saber la distribuci√≥n de la data.
.
Entre los tipos m√°s importantes tenemos:

Min-max
Clipping
Winsorizing
Z-Score

Z- Score en probabilidad se denomina Variable normal estandarizada. Se transforma la distribucion a una distribucion estandarizada y para cada valor de Z se encuentran tabulados los valores de la probabilidad (Estos valores salen de la integracion de la funcion de densidad de una distribucion normal y la suma del area bajo la curva).

Pipelines de procesamiento para variables num√©ricas

¬øQu√© es Pipelines de procesamiento para variables num√©ricas?
La normalizaci√≥n es un proceso se utiliza pre machin learning para la preparaci√≥n de los datos. El objetivo es cambiar las columnas num√©ricas del mismo rango en conjunto de datos con una escala com√∫n.

Escalamiento lineal
¬øPor qu√© emplear?
Modelos de machine Leaning efiencientes en el

Rango est√°ndar [ -1, 1 ]
¬øHay diferentes tipos?
max - min, Clipping, Z-score, Winsorizing, etc.
¬øCu√°ndo utilizarlos?
Cuando los datos tienen una distribuci√≥n parecida.
O los datos son sim√©tricos.

¬øQu√© es una Pipeline de Datos?

Una pipeline de datos es una construcci√≥n l√≥gica que representa un proceso dividido en fases. Las pipelines de datos se caracterizan por definir el conjunto de pasos o fases y las tecnolog√≠as involucradas en un proceso de movimiento o procesamiento de datos.

Las pipelines de datos son necesarias ya que no debemos analizar los datos en los mismos sistemas donde se crean. El proceso de anal√≠tica es costoso computacionalmente, por lo que se separa para evitar perjudicar el rendimiento del servicio. De esta forma, tenemos sistemas OLTP, encargados de capturar y crear datos, y sistemas OLAP, encargados de analizar los datos.

Por ejemplo, un sistema OLTP puede ser un CRM, mientras que un sistema OLAP ser√° un Data Warehouse.

Ejemplo de Pipeline de Datos

Como ejemplo, podemos pensar en las APIs de ingesta para obtener los datos. Esta API es el punto de partida, y podr√≠a enviar los datos a un topic de Apache Kafka. Kafka act√∫a aqu√≠ como un buffer para el siguiente paso.

Despu√©s, una tecnolog√≠a de procesamiento, que puede ser streaming o batch, leer√° los datos de nuestro buffer. Por ejemplo, Apache Spark realizar√° anal√≠tica sobre estos datos.

Por √∫ltimo, la pipeline termina con el resultado almacenado de forma persistente en una base de datos como HBase o en un sistema de ficheros distribuido como HDFS.

Una vez que nuestros datos est√°n persistidos se encuentran listos para ser usados. Podr√≠amos implementar una aplicaci√≥n web que muestra estos datos en un dashboard como Grafana o consultarlos con herramientas de visualizaci√≥n y BI.

Los movimientos de datos entre estos sistemas forman pipelines de datos y son


Transformaci√≥n no lineal
¬øPor qu√© usarlos?
En el caso donde haya datos fuertemente sesgados y no sim√©tricos.
.

Algunos tipos:
Log√≠stica: los valores de la columna se transforman mediante la siguiente f√≥rmula:
log
.

LogNormal: esta opci√≥n convierte todos los valores a una escala logar√≠tmica normal. Los valores1 de la columna se transforman mediante la siguiente f√≥rmula:
lognormal
Aqu√≠ Œº y œÉ son los par√°metros de la distribuci√≥n, calculados emp√≠ricamente a partir de los datos como estimaciones de m√°xima verosimilitud, para cada columna por separado.

.

TanH: todos los valores se convierten a una tangente hiperb√≥lica. Los valores de la columna se transforman mediante la siguiente f√≥rmula:
Tha
.

¬øCu√°ndo usarlos?
Justo antes de aplicar el escalamiento lineal, las transformaciones no lineales solo son para que nuestros datos queden lineales para luego aplicar la normalizaci√≥n lineal. Siempre se debe aplicar la normalizaci√≥n lineal.


Log√≠stica: $$ x_s = \frac{1}{1+e^{-x}} $$
Tan H: $$ p(k|x;\Theta) = \frac{[E(Y|x)]^k*e^{-E(Y|x)}}{k!} $$


Correlaciones
¬øQu√© es la correlaci√≥n?
La correlaci√≥n es una medida estad√≠stica que expresa hasta qu√© punto dos variables est√°n relacionadas linealmente (esto es, cambian conjuntamente a una tasa constante).
¬øQu√© es la covarianza?
Es un valor que indica el grado de variaci√≥n conjunta de dos variables aleatorias respecto a sus medias.
¬øQu√© es el coeficiente de correlaci√≥n?
El coeficiente de correlaci√≥n es la medida espec√≠fica que cuantifica la intensidad de la relaci√≥n lineal entre dos variables en un an√°lisis de correlaci√≥n.

Dato curioso:
Lo que meciona Pacho al inicio de la clase, en econometr√≠a se le conoce como multicolinealidad que es una situaci√≥n en la que se presenta una fuerte correlaci√≥n entre variables del modelo.

Hay 2 tipos de multicolinealidad:
Multicolinealidad exacta: Hay colinealidad exacta, cuando una o m√°s variables, son una combinaci√≥n lineal de otra, es decir, existe un coeficiente de correlaci√≥n entre estas dos variables de 1.

Multicolinealidad aproximada: Hay colinealidad aproximada, cuando una o m√°s variables, no son exactamente una combinaci√≥n lineal de la otra, pero existe un coeficiente de determinaci√≥n entre estas variables muy cercano al uno.


Notas de la clase:
La grafica splot nos permit√≠a visualizar como cambiaba una variable respecto a la otra.
Decimos que est√°n correlacionadas si una varia de forma muy definida respecto a otra
.
¬øQu√© es correlaci√≥n?
La correlaci√≥n es una medida estad√≠stica que expresa hasta qu√© punto dos variables est√°n relacionadas linealmente (esto es, cambian conjuntamente a una tasa constante).
.
¬øPor qu√© es importante la correlaci√≥n?
Si se tienen 2 variables que est√°n correlacionadas entre s√≠, no tiene sentido incluir ambas variables en un modelo de ML porque probablemente las 2 van a aportar la misma informaci√≥n si la correlaci√≥n es muy alta. En ese caso se elimina a una de las 2, b√°sicamente en eso consiste la reducci√≥n de datos.
.
¬øQu√© es la covarianza?
Es un valor que indica el grado de variaci√≥n conjunta de dos variables aleatorias respecto a sus medias
.
¬øQu√© es el coeficiente de correlaci√≥n?
Es una medida de dependencia lineal entre 2 variables. A diferencia de la covarianza es independiente de la escala de medida de las variables.

Si las variables tienen un coeficiente de correlaci√≥n muy alto las variables tienen una correlaci√≥n muy elevada.
Si el coeficiente de correlaci√≥n es muy bajo las variables tienen una correlaci√≥n muy baja.
.
Frase:
"Cum hoc ergo propter hoc"
Causaci√≥n no est√° asociado don correlaci√≥n
Correlaci√≥n no implica causaci√≥n


Como viste en la clase anterior, cuando tenemos un conjunto de datos con muchas variables, la matriz de covarianza es el objeto matem√°tico que permite identificar cu√°les variables est√°n altamente correlacionadas.

Cuando dos variables est√°n altamente correlacionadas, quiere decir que aportan b√°sicamente la misma informaci√≥n del problema y eso podr√≠a indicar que solo necesitar√≠amos una sola de ellas. En la pr√≥xima clase veremos que esa reducci√≥n de variables se puede hacer con una t√©cnica matem√°tica denominada PCA (principal component analysis).

Esta t√©cnica est√° basada en un concepto del √°lgebra de vectores y matrices, que llamamos el c√°lculo de los valores propios de una matriz, y en esta lectura profundizaremos sobre qu√© significa ese procedimiento.

Repaso de matrices
Las matrices en general son objetos matem√°ticos que tienen un cierto n√∫mero de filas y columnas (estos n√∫meros los denominamos dimensiones de la matriz).

Las matrices tienen una operaci√≥n especial, que llamamos transponer, la cual consiste en ubicar cada fila como una columna en una nueva matriz, el resultado de una transposici√≥n se denomina matriz transpuesta y se ve as√≠:

https://i.imgur.com/zEGhv9B.png
As√≠ tambi√©n, entre las matrices podemos definir reglas de suma y resta de forma similar a como hacemos con los n√∫meros naturales o decimales, con una condici√≥n especial: ambas matrices deben tener las mismas dimensiones y cuando las dimensiones de una matriz son iguales entre ellas (# filas = # columnas) decimos que la matriz es cuadrada.

Con esto en mente resumimos lo anterior con un ejemplo de suma entre dos matrices cuadradas as√≠:

https://i.imgur.com/EINCqZt.png
Donde vemos que la suma de matrices se hace elemento a elemento para dar origen a otra matriz con las mismas dimensiones. Entonces para obtener el elemento de la primera fila y primera columna de la matriz suma, se suman los elementos correspondientes a cada matriz ubicados en la primera fila y primera columna:

1 + (-1) = 0

Ahora bien, las matrices tambi√©n tienen una operaci√≥n de multiplicaci√≥n entre ellas que es m√°s compleja de definir que la suma, sin embargo aqu√≠ vamos a desglosarla. Vamos a reemplazar los elementos num√©ricos de las matrices del ejemplo anterior por variables algebraicas, indicando que pueden ser cualquier n√∫mero para as√≠ exponer el proceso con la mayor generalidad posible. De esta manera, vamos a definir el producto de dos matrices cuadradas de tal manera que el resultado sea otra matriz de las mismas dimensiones as√≠:

https://i.imgur.com/DOf9N1J.png
Donde cada expresi√≥n algebraica tiene la forma de dos √≠ndices que denotan la fila y columna donde est√° posicionado el n√∫mero, respectivamente. Y la manera de calcular cada elemento de la matriz resultante viene dado por una regla sencilla que ilustraremos con el siguiente ejemplo:

https://i.imgur.com/pA7qH2a.png
Que equivale a decir que el elemento de la fila 1 y columna 1 de la matriz resultado se calcula como la suma de los productos de los elementos de la primera fila de la primera matriz por los elementos de la primera columna de la segunda matriz

https://i.imgur.com/pjuZwlE.png
Veamos otro ejemplo para tenerlo m√°s claro:

https://i.imgur.com/2WoNK6j.png
En este caso el elemento de la fila 1 y columna 2 de la matriz resultado se calcula como la suma de los productos de los elementos de la primera fila de la primera matriz por los elementos de la segunda columna de la segunda matriz.

En python el producto de matrices se calcula f√°cil usando la librer√≠a numpy:

np.matmul(A, B)
Donde, por ejemplo, una matriz:

https://i.imgur.com/BJPv2tR.png
Se escribe en python como:

A = np.array([[2, 4], [-1, 2]])
Esta definici√≥n se hizo para matrices de dos filas y dos columnas que denominamos matrices 2x2. Pero se aplica de la misma manera para matrices cuadradas de cualquier tama√±o NxN. Por ahora solo nos interesar√° esta definici√≥n restringida para matrices cuadradas, pero en cualquier curso de √°lgebra de matrices podr√°s darte cuenta de que esta definici√≥n se puede hacer m√°s general para matrices que no sean necesariamente cuadradas.

Ahora, as√≠ como cada n√∫mero tiene su inverso, donde el inverso se define como aquel n√∫mero tal que la multiplicaci√≥n de ambos da 1:

https://i.imgur.com/SGKZXka.png
En este caso ‚Öô es el inverso de 6. As√≠ tambi√©n, las matrices tambi√©n pueden tener su inversa (aunque no siempre), la matriz inversa A-1de una matriz dada A se define como aquella matriz donde (supongamos que A es 2x2):

https://i.imgur.com/kEiv8fB.png
El c√°lculo de matriz inversa se hace r√°pido usando NumPy nuevamente as√≠:

A = np.array([[2, 4], [-1, 2]])
Ainversa = np.linalg.inv(A)
Donde, el resultado de Ainversa en este caso particular ser√≠a:

array([[ 0.25 , -0.5  ],
	[ 0.125,  0.25 ]])
Para comprobar que esto est√° bien, puedes multiplicar ambas matrices para ver que da lo correcto:

np.matmul(A, Ainversa)
Repaso de Vectores
Como caso particular adicional a la definici√≥n anterior, consideremos el producto de una matriz cuadrada por un vector (aqu√≠ entendemos un vector como una matriz de una sola columna, tambi√©n se le denomina por eso vectores columna en muchos libros de √°lgebra lineal) cuya longitud es igual al n√∫mero de filas de la matriz as√≠:

https://i.imgur.com/1aFGNYg.png
Donde definimos que el producto de una matriz por un vector resulta en otro vector de las mismas dimensiones (filas). Y la regla que consideramos para el caso de matrices cuadradas tambi√©n aplica de manera que los elementos del vector resultante se obtendr√≠an de multiplicar filas por columnas as√≠:

https://i.imgur.com/9vuSATV.png
Tambi√©n tenemos una operaci√≥n entre vectores que denominamos el producto punto o producto interior. Normalmente al considerar esta definici√≥n se representa el primer vector como una sola fila y el segundo como una sola columna as√≠ (sigamos pensando con base en el ejemplo anterior de la matriz por el vector, pero ahora la matriz solo tiene una fila):

https://i.imgur.com/596zIHK.png
Y como ya te est√°s dando cuenta (teniendo en mente la misma definici√≥n de multiplicaci√≥n de matrices) al solo haber una fila en la primera matriz y una columna en la segunda matriz, el resultado solo podr√° tener un elemento y es por esto que el resultado de multiplicar dos vectores de esta manera es siempre un n√∫mero:

https://i.imgur.com/IGNqY7n.png
Simplifiquemos la notaci√≥n as√≠:

https://i.imgur.com/ONdFb8h.png
Y esto nos recuerda la cl√°sica regla de multiplicar vectores como x por x m√°s y por y. Y si los vectores tienen m√°s dimensiones, entonces ‚Ä¶ m√°s z por z y as√≠. Recuerda que la notaci√≥n simplificada es porque ahora tenemos que la primera componente es el eje X del vector y la segunda componente el eje Y del vector cuando lo dibujamos en un plano cartesiano.

https://i.imgur.com/bP7C40X.png
Ahora, cuando pensamos en multiplicar un vector por el mismo, la misma definici√≥n aplica:

https://i.imgur.com/doQIHFe.png
Y nos damos cuenta de que esto se relaciona con el Teorema de Pit√°goras al ver que el producto de un vector por el mismo nos da el cuadrado de la longitud de la flecha que representa al vector en el plano cartesiano:

https://i.imgur.com/7441gI8.png
https://i.imgur.com/qzk7KN3.png
As√≠ vemos que la longitud de un vector, tambi√©n conocida como norma del vector se calcula como:

https://i.imgur.com/OUmWoRs.png
Listo, con esto terminamos un repaso b√°sico de lo m√≠nimo de matrices y vectores para lo que viene.

Vectores y Valores propios de una matriz
En √°lgebra lineal podemos tener ecuaciones donde la inc√≥gnita es un vector, supongamos la siguiente ecuaci√≥n:

https://i.imgur.com/mee9AMt.png
Aqu√≠ A es una matriz cuadrada NxN cuyos elementos conocemos perfectamente y X es un vector columna cuyas componentes desconocemos. Aqu√≠ recordemos que multiplicar un vector por un n√∫mero es simplemente multiplicar cada componente del vector por dicho n√∫mero.

Entonces lo que esta ecuaci√≥n nos pregunta es:

¬øExisten vectores X tales que al multiplicarlos por la matriz A eso es equivalente a simplemente multiplicarlos por un n√∫mero?

Si tal vector existe y est√° asociado a un valor espec√≠fico de Œõ, entonces decimos que el vector X es un vector propio de la matriz A y Œõ es su valor propio correspondiente.

Consideremos esto para el caso de una matriz 2 x 2, como la siguiente:

https://i.imgur.com/5AlP07v.png
Esto se traduce en el sistema de ecuaciones (haciendo el producto matriz por vector):

https://i.imgur.com/LVyLKYe.png
Aqu√≠ entonces debemos encontrar las combinaciones de x, y e que satisfacen el sistema de ecuaciones. En general, hacer esto requiere otros conceptos m√°s detallados del √°lgebra de matrices como el c√°lculo de determinantes y resolver ecuaciones polinomiales cuya explicaci√≥n solo puede dejarse a un curso exclusivo de √°lgebra lineal. Pero no te preocupes, ya que podemos hacer este c√°lculo de manera r√°pida con python as√≠:

import numpy as np

A = np.array([[1, 2], [1, 0]])
values, vectors = np.linalg.eig(A)
Donde la matriz A contiene los elementos exactos de la matriz anterior y el comando np.linalg.eig(A) lo que hace es calcular directamente los valores y vectores propios, llamados values y vectors en el c√≥digo, respectivamente.

Ver√°s que esta matriz tiene dos valores propios:

array([ 2., -1.])
Con sus respectivos vectores propios asociados:

array([[ 0.89442719, -0.70710678 ],
	[ 0.4472136 , 0.70710678 ]])
Aqu√≠ es importante anotar que los vectores que entrega la funci√≥n np.linalg.eig(A) son vectores columna de manera que los elementos de la primera columna de vectors corresponden con el primer valor de values y as√≠ sucesivamente. Entonces en nuestro lenguaje matem√°tico usual, escribimos las dos soluciones como:

vector_uno
vector_dos
Puedes verificar que cada vector y su respectivo valor propio cumplen la ecuaci√≥n original ejecutando cada parte as√≠:

np.matmul(A, vectors.T[1])
Que te da como resultado:

array([ 0.70710678, -0.70710678])
Mientras que por otro lado calculando:

values[1]*vectors.T[1]
Resulta en lo mismo:

array([ 0.70710678, -0.70710678])
Donde hemos considerado el segundo vector y valor propio respectivamente tomando Œª = -1 y el vector inc√≥gnita X igual a vectors.T[1].

Uno de los hechos m√°s importantes de obtener los vectores y valores propios de una matriz es poder diagonalizarla. En general se define que una matriz A es diagonalizable si es posible escribirla como el producto de:


Donde D es una matriz diagonal (matriz donde todos los elementos por fuera de la diagonal son cero), un ejemplo de matriz diagonal ser√≠a:


Y aqu√≠ un resultado matem√°tico bien conocido es que si una matriz es diagonalizable, la matriz D se construye colocando sus valores propios en la diagonal y la matriz P se construye colocando en cada columna el vector propio,siguiendo el mismo orden de valores propios correspondientes de la matriz D, as√≠:


Lo importante de estudiar este procedimiento en nuestro curso, es que cuando aplicamos este c√°lculo de vectores y valores propios a una matriz de covarianza, los vectores representan las direcciones a lo largo de las cuales percibimos la mayor cantidad de varianza de ese conjunto de datos, donde la cantidad de varianza es proporcional al valor propio de cada vector propio.

Y es importante tener en cuenta que este procedimiento aplica para un conjunto de datos con N variables al que le corresponde una matriz de covarianza de tama√±o NxN.

Ahora, el √∫ltimo factor importante de esta t√©cnica es que para matrices de covarianza, sus vectores propios siempre son independientes unos de otros y esto es justamente lo que queremos en un proceso de reducci√≥n de variables, porque direcciones independientes implica que estos vectores representan nuevas variables cuya correlaci√≥n es la m√°s baja posible y as√≠ cada nueva variable es lo m√°s representativa posible.

En √°lgebra lineal se dice m√°s precisamente que los vectores propios de una matriz de covarianza son ortogonales y esto quiere decir que el producto interno de cualquier par de estos vectores siempre da como resultado cero:


Como consecuencia la matriz se denomina matriz ortogonal, y se sabe en matem√°ticas que la inversa de una matriz ortogonal es igual a la transpuesta, de manera que:

